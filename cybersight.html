<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>CyberSight: A/V Scanner</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: 'Courier New', monospace; }
        
        /* 1. Camera Feed */
        video {
            position: absolute; top: 0; left: 0;
            width: 100vw; height: 100vh;
            object-fit: cover;
            z-index: 1;
        }

        /* 2. HUD Layer (Boxes & Text) */
        #hud-canvas {
            position: absolute; top: 0; left: 0;
            width: 100vw; height: 100vh;
            z-index: 2;
        }

        /* 3. Spectrogram Panel (Bottom) */
        #spectro-panel {
            position: absolute; bottom: 0; left: 0;
            width: 100%; height: 25vh;
            background: rgba(0, 10, 0, 0.6);
            border-top: 2px solid #00ff00;
            z-index: 3;
            display: flex;
        }
        #spectro-canvas { width: 100%; height: 100%; }

        /* 4. Start Screen Overlay */
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: #050505; z-index: 10;
            display: flex; justify-content: center; align-items: center; 
            flex-direction: column; color: #0f0; text-align: center;
        }
        h1 { margin-bottom: 5px; text-shadow: 0 0 10px #0f0; }
        p { color: #aaa; max-width: 300px; margin-bottom: 20px; }
        
        button {
            padding: 15px 30px; font-size: 18px; font-weight: bold; font-family: inherit;
            background: #000; border: 1px solid #0f0; color: #0f0; 
            cursor: pointer; box-shadow: 0 0 10px #0f0;
            display: none; /* Hidden until AI loads */
        }
        button:hover { background: #0f0; color: #000; }
        
        #status-log { font-size: 12px; color: #008800; margin-top: 10px; }
    </style>
</head>
<body>

    <div id="overlay">
        <h1>CYBER SIGHT</h1>
        <p>Object Detection + Stereo Sound Triangulation</p>
        <p style="color:yellow; font-size:12px;">âš  USE LANDSCAPE MODE FOR STEREO</p>
        <div id="loading-msg">Initializing Neural Net...</div>
        <button id="start-btn">ENGAGE SENSORS</button>
        <div id="status-log"></div>
    </div>

    <video id="cam" playsinline autoplay muted></video>
    <canvas id="hud-canvas"></canvas>
    
    <div id="spectro-panel">
        <canvas id="spectro-canvas"></canvas>
    </div>

    <script>
        // --- GLOBAL VARIABLES ---
        let video, hudCanvas, hudCtx, spectroCanvas, spectroCtx;
        let model = null;
        let isRunning = false;
        
        // Audio Vars
        let audioCtx, source, splitter;
        let leftAnalyser, rightAnalyser, mainAnalyser;
        let leftData, rightData, mainData;
        
        // --- 1. SYSTEM BOOT ---
        window.onload = async () => {
            try {
                // Load AI Model
                model = await cocoSsd.load();
                document.getElementById('loading-msg').innerText = "SYSTEM READY";
                document.getElementById('start-btn').style.display = 'block';
            } catch (err) {
                document.getElementById('loading-msg').style.color = 'red';
                document.getElementById('loading-msg').innerText = "AI ERROR: " + err;
            }
        };

        document.getElementById('start-btn').addEventListener('click', startApp);

        async function startApp() {
            document.getElementById('overlay').style.display = 'none';

            // Setup Canvases
            video = document.getElementById('cam');
            hudCanvas = document.getElementById('hud-canvas');
            hudCtx = hudCanvas.getContext('2d');
            spectroCanvas = document.getElementById('spectro-canvas');
            spectroCtx = spectroCanvas.getContext('2d');
            
            resize();
            window.addEventListener('resize', resize);

            try {
                // A. Request Camera & Microphone
                // Note: We ask for 2 channels to enable stereo if hardware supports it
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'environment' }, 
                    audio: { 
                        channelCount: 2, 
                        echoCancellation: false, 
                        autoGainControl: false, 
                        noiseSuppression: false 
                    } 
                });
                video.srcObject = stream;

                // B. Init Audio Engine
                setupAudio(stream);

                // C. Start Processing Loops
                video.onloadeddata = () => {
                    isRunning = true;
                    detectFrame();    // Visual Processing
                    drawSpectrogram(); // Audio Processing
                };

            } catch (err) {
                alert("Hardware Access Denied: " + err);
            }
        }

        function resize() {
            hudCanvas.width = window.innerWidth;
            hudCanvas.height = window.innerHeight;
            spectroCanvas.width = document.getElementById('spectro-panel').offsetWidth;
            spectroCanvas.height = document.getElementById('spectro-panel').offsetHeight;
        }

        // --- 2. AUDIO ENGINE (STEREO SETUP) ---
        function setupAudio(stream) {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            source = audioCtx.createMediaStreamSource(stream);

            // Channel Splitter (Left vs Right)
            splitter = audioCtx.createChannelSplitter(2);
            source.connect(splitter);

            // Left Channel
            leftAnalyser = audioCtx.createAnalyser();
            leftAnalyser.fftSize = 256;
            splitter.connect(leftAnalyser, 0);
            leftData = new Uint8Array(leftAnalyser.frequencyBinCount);

            // Right Channel
            rightAnalyser = audioCtx.createAnalyser();
            rightAnalyser.fftSize = 256;
            splitter.connect(rightAnalyser, 1);
            rightData = new Uint8Array(rightAnalyser.frequencyBinCount);

            // Main Channel (Combined for Spectrogram)
            mainAnalyser = audioCtx.createAnalyser();
            mainAnalyser.fftSize = 512;
            source.connect(mainAnalyser);
            mainData = new Uint8Array(mainAnalyser.frequencyBinCount);
        }

        // --- 3. THE "BRAIN" (Object Detection + Direction Logic) ---
        async function detectFrame() {
            if (!isRunning) return;

            // A. Detect Objects
            const predictions = await model.detect(video);

            // B. Analyze Audio Volumes
            const volL = getVol(leftAnalyser, leftData);
            const volR = getVol(rightAnalyser, rightData);
            const totalVol = (volL + volR) / 2;
            
            // Calculate dB (Rough approximation)
            // 0-255 mapped to -100dB to 0dB
            const db = (totalVol > 0) ? (20 * Math.log10(totalVol / 255)) * 2 : -100;
            const dbDisplay = Math.max(-100, db + 60); // Offset for display comfort

            // C. Determine Direction
            let direction = "CENTER";
            // Threshold: One side must be 20% louder to count as directional
            if (volL > volR * 1.2 && volL > 10) direction = "LEFT";
            else if (volR > volL * 1.2 && volR > 10) direction = "RIGHT";

            // D. Draw HUD
            hudCtx.clearRect(0, 0, hudCanvas.width, hudCanvas.height);
            
            // Draw Directional Arrows (The "Seeker")
            if (totalVol > 15) { // Only if sound exists
                hudCtx.font = "bold 40px Courier New";
                hudCtx.fillStyle = "rgba(0, 255, 0, 0.7)";
                
                if (direction === "LEFT") {
                    hudCtx.fillText("<< DETECTING SIGNAL", 20, window.innerHeight / 2);
                } else if (direction === "RIGHT") {
                    const txt = "DETECTING SIGNAL >>";
                    hudCtx.fillText(txt, window.innerWidth - hudCtx.measureText(txt).width - 20, window.innerHeight / 2);
                } else {
                    // CENTERED: Draw Crosshair
                    const cx = window.innerWidth / 2;
                    const cy = window.innerHeight / 2;
                    hudCtx.strokeStyle = "rgba(0, 255, 0, 0.5)";
                    hudCtx.lineWidth = 2;
                    hudCtx.beginPath();
                    // Cross
                    hudCtx.moveTo(cx - 30, cy); hudCtx.lineTo(cx + 30, cy);
                    hudCtx.moveTo(cx, cy - 30); hudCtx.lineTo(cx, cy + 30);
                    // Circle
                    hudCtx.arc(cx, cy, 50, 0, 2*Math.PI);
                    hudCtx.stroke();
                }
            }

            // E. Process Identified Objects
            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const label = prediction.class.toUpperCase();
                
                // Centering Check
                const boxCenterX = x + (width / 2);
                const screenCenterX = window.innerWidth / 2;
                
                // STIMULUS LOGIC:
                // 1. Is it Loud?
                // 2. Is Audio Center?
                // 3. Is Visual Center?
                const isLoud = dbDisplay > -20; // Adjusted threshold
                const isAudioCentered = direction === "CENTER";
                const isVisualCentered = Math.abs(boxCenterX - screenCenterX) < 200;

                let color = '#00ff00';
                let text = label;
                let lineWidth = 2;

                if (isLoud && isAudioCentered && isVisualCentered) {
                    // TARGET LOCK
                    color = '#ff0000';
                    text = `SOURCE: ${label} [${dbDisplay.toFixed(0)} dB]`;
                    lineWidth = 5;
                    
                    // Jitter effect
                    const rx = (Math.random() - 0.5) * 10;
                    const ry = (Math.random() - 0.5) * 10;
                    
                    hudCtx.strokeRect(x + rx, y + ry, width, height);
                } else {
                    // PASSIVE SCAN
                    hudCtx.strokeRect(x, y, width, height);
                }

                hudCtx.lineWidth = lineWidth;
                hudCtx.strokeStyle = color;
                
                // Draw Label Background
                hudCtx.fillStyle = color;
                const textWidth = hudCtx.measureText(text).width;
                hudCtx.fillRect(x, y - 25, textWidth + 10, 25);
                
                // Draw Label Text
                hudCtx.fillStyle = '#000';
                hudCtx.font = "bold 16px Courier New";
                hudCtx.fillText(text, x + 5, y - 7);
            });

            requestAnimationFrame(detectFrame);
        }

        // --- 4. SPECTROGRAM (Visualizer) ---
        function drawSpectrogram() {
            if (!isRunning) return;
            requestAnimationFrame(drawSpectrogram);

            mainAnalyser.getByteFrequencyData(mainData);
            
            const w = spectroCanvas.width;
            const h = spectroCanvas.height;
            const barWidth = w / mainData.length;

            // Fade out previous frame
            spectroCtx.fillStyle = 'rgba(0, 10, 0, 0.2)';
            spectroCtx.fillRect(0, 0, w, h);

            // Draw Bars
            for (let i = 0; i < mainData.length; i++) {
                const val = mainData[i];
                const percent = val / 255;
                const barH = h * percent;

                // Color Map: Green -> Yellow -> Red
                const hue = 120 - (percent * 120);
                spectroCtx.fillStyle = `hsl(${hue}, 100%, 50%)`;
                spectroCtx.fillRect(i * barWidth, h - barH, barWidth, barH);
            }
            
            // Draw Waveform Overlay
            spectroCtx.beginPath();
            spectroCtx.strokeStyle = "rgba(255, 255, 255, 0.5)";
            spectroCtx.lineWidth = 1;
            spectroCtx.moveTo(0, h);
            for (let i = 0; i < mainData.length; i++) {
                const percent = mainData[i] / 255;
                spectroCtx.lineTo(i * barWidth, h - (h * percent));
            }
            spectroCtx.stroke();
        }

        // Utility: Get Average Volume from Analyzer Node
        function getVol(analyser, array) {
            if(!analyser) return 0;
            analyser.getByteFrequencyData(array);
            let sum = 0;
            for(let i=0; i<array.length; i++) sum += array[i];
            return sum / array.length;
        }

    </script>
</body>
</html>
