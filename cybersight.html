<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>CyberSight v1.1: Transparent AR</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: 'Courier New', monospace; }
        
        /* 1. Camera Feed - Fills screen */
        video {
            position: absolute; top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: cover; /* Ensures full coverage without stretching */
            z-index: 1;
        }

        /* 2. HUD Layer (Boxes & Text) */
        #hud-canvas {
            position: absolute; top: 0; left: 0;
            width: 100%; height: 100%;
            z-index: 2;
            pointer-events: none; /* Let touches pass through */
        }

        /* 3. Spectrogram Panel (Bottom Overlay) */
        #spectro-panel {
            position: absolute; bottom: 0; left: 0;
            width: 100%; height: 30vh; /* Slightly taller for legends */
            /* Background removed for transparency */
            background: transparent; 
            /* Subtle top border for separation */
            border-top: 1px solid rgba(0, 255, 0, 0.3);
            z-index: 3;
            display: flex;
            pointer-events: none;
        }
        #spectro-canvas { width: 100%; height: 100%; }

        /* 4. Start Screen Overlay */
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: #050505; z-index: 10;
            display: flex; justify-content: center; align-items: center; 
            flex-direction: column; color: #0f0; text-align: center;
        }
        h1 { margin-bottom: 5px; text-shadow: 0 0 10px #0f0; }
        p { color: #aaa; max-width: 300px; margin-bottom: 20px; }
        
        button {
            padding: 15px 30px; font-size: 18px; font-weight: bold; font-family: inherit;
            background: #000; border: 1px solid #0f0; color: #0f0; 
            cursor: pointer; box-shadow: 0 0 10px #0f0;
            display: none; /* Hidden until AI loads */
        }
        button:hover { background: #0f0; color: #000; }
        
        #status-log { font-size: 12px; color: #008800; margin-top: 10px; }
    </style>
</head>
<body>

    <div id="overlay">
        <h1>CYBER SIGHT v1.1</h1>
        <p>Transparent Overlay + Stereo Tracking</p>
        <p style="color:yellow; font-size:12px;">âš  USE LANDSCAPE MODE FOR STEREO DETECTION</p>
        <div id="loading-msg">Initializing Neural Net...</div>
        <button id="start-btn">ENGAGE SENSORS</button>
        <div id="status-log"></div>
    </div>

    <video id="cam" playsinline autoplay muted></video>
    <canvas id="hud-canvas"></canvas>
    
    <div id="spectro-panel">
        <canvas id="spectro-canvas"></canvas>
    </div>

    <script>
        // --- GLOBAL VARIABLES ---
        let video, hudCanvas, hudCtx, spectroCanvas, spectroCtx;
        let model = null;
        let isRunning = false;
        
        // Audio Vars
        let audioCtx, source, splitter;
        let leftAnalyser, rightAnalyser, mainAnalyser;
        let leftData, rightData, mainData;
        
        // --- 1. SYSTEM BOOT ---
        window.onload = async () => {
            try {
                // Load AI Model
                model = await cocoSsd.load();
                document.getElementById('loading-msg').innerText = "SYSTEM READY";
                document.getElementById('start-btn').style.display = 'block';
            } catch (err) {
                document.getElementById('loading-msg').style.color = 'red';
                document.getElementById('loading-msg').innerText = "AI ERROR: " + err;
            }
        };

        document.getElementById('start-btn').addEventListener('click', startApp);

        async function startApp() {
            document.getElementById('overlay').style.display = 'none';

            // Setup Canvases
            video = document.getElementById('cam');
            hudCanvas = document.getElementById('hud-canvas');
            hudCtx = hudCanvas.getContext('2d');
            spectroCanvas = document.getElementById('spectro-canvas');
            spectroCtx = spectroCanvas.getContext('2d');
            
            resize();
            window.addEventListener('resize', resize);

            try {
                // A. Request Camera & Microphone (Stereo preference)
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'environment' }, 
                    audio: { 
                        channelCount: 2, 
                        echoCancellation: false, 
                        autoGainControl: false, 
                        noiseSuppression: false 
                    } 
                });
                video.srcObject = stream;

                // B. Init Audio Engine
                setupAudio(stream);

                // C. Start Processing Loops
                video.onloadeddata = () => {
                    isRunning = true;
                    detectFrame();    // Visual Processing
                    drawSpectrogram(); // Audio Processing
                };

            } catch (err) {
                alert("Hardware Access Denied: " + err);
            }
        }

        function resize() {
            // Ensure canvases match window size exactly
            hudCanvas.width = window.innerWidth;
            hudCanvas.height = window.innerHeight;
            spectroCanvas.width = document.getElementById('spectro-panel').offsetWidth;
            spectroCanvas.height = document.getElementById('spectro-panel').offsetHeight;
        }

        // --- 2. AUDIO ENGINE (STEREO SETUP) ---
        function setupAudio(stream) {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            source = audioCtx.createMediaStreamSource(stream);

            // Channel Splitter (Left vs Right)
            splitter = audioCtx.createChannelSplitter(2);
            source.connect(splitter);

            // Left Channel
            leftAnalyser = audioCtx.createAnalyser();
            leftAnalyser.fftSize = 256;
            splitter.connect(leftAnalyser, 0);
            leftData = new Uint8Array(leftAnalyser.frequencyBinCount);

            // Right Channel
            rightAnalyser = audioCtx.createAnalyser();
            rightAnalyser.fftSize = 256;
            splitter.connect(rightAnalyser, 1);
            rightData = new Uint8Array(rightAnalyser.frequencyBinCount);

            // Main Channel (Combined for Spectrogram)
            mainAnalyser = audioCtx.createAnalyser();
            mainAnalyser.fftSize = 512; // Higher resolution for visualizer
            source.connect(mainAnalyser);
            mainData = new Uint8Array(mainAnalyser.frequencyBinCount);
        }

        // --- 3. THE "BRAIN" (Object Detection + Direction Logic) ---
        async function detectFrame() {
            if (!isRunning) return;

            // A. Detect Objects
            const predictions = await model.detect(video);

            // B. Analyze Audio Volumes
            const volL = getVol(leftAnalyser, leftData);
            const volR = getVol(rightAnalyser, rightData);
            const totalVol = (volL + volR) / 2;
            
            // Calculate dB (Rough approximation for display)
            const db = (totalVol > 0) ? (20 * Math.log10(totalVol / 255)) * 2 : -100;
            const dbDisplay = Math.max(-100, db + 60);

            // C. Determine Direction
            let direction = "CENTER";
            // Threshold: One side must be ~20% louder
            if (volL > volR * 1.2 && volL > 5) direction = "LEFT";
            else if (volR > volL * 1.2 && volR > 5) direction = "RIGHT";

            // D. Draw HUD
            hudCtx.clearRect(0, 0, hudCanvas.width, hudCanvas.height);
            
            // Draw Directional Arrows (The "Seeker")
            if (totalVol > 10) {
                hudCtx.font = "bold 30px Courier New";
                hudCtx.fillStyle = "rgba(0, 255, 0, 0.7)";
                const cy = window.innerHeight / 2;
                
                if (direction === "LEFT") {
                    hudCtx.fillText("<< SIGNAL LEFT", 20, cy);
                } else if (direction === "RIGHT") {
                    const txt = "SIGNAL RIGHT >>";
                    hudCtx.fillText(txt, window.innerWidth - hudCtx.measureText(txt).width - 20, cy);
                } else {
                    // CENTERED: Draw Crosshair
                    const cx = window.innerWidth / 2;
                    hudCtx.strokeStyle = "rgba(0, 255, 0, 0.5)";
                    hudCtx.lineWidth = 2;
                    hudCtx.beginPath();
                    hudCtx.moveTo(cx - 30, cy); hudCtx.lineTo(cx + 30, cy);
                    hudCtx.moveTo(cx, cy - 30); hudCtx.lineTo(cx, cy + 30);
                    hudCtx.arc(cx, cy, 50, 0, 2*Math.PI);
                    hudCtx.stroke();
                }
            }

            // E. Process Identified Objects
            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const label = prediction.class.toUpperCase();
                
                const boxCenterX = x + (width / 2);
                const screenCenterX = window.innerWidth / 2;
                
                // STIMULUS LOGIC: Loud + Centered Audio + Centered Visual
                const isLoud = dbDisplay > -25; 
                const isAudioCentered = direction === "CENTER";
                const isVisualCentered = Math.abs(boxCenterX - screenCenterX) < 250;

                let color = '#00ff00';
                let text = label;
                let lineWidth = 2;

                if (isLoud && isAudioCentered && isVisualCentered) {
                    // TARGET LOCK
                    color = '#ff0000';
                    text = `SOURCE: ${label} [${dbDisplay.toFixed(0)}dB]`;
                    lineWidth = 4;
                    
                    // Jitter effect
                    const rx = (Math.random() - 0.5) * 8;
                    const ry = (Math.random() - 0.5) * 8;
                    hudCtx.strokeRect(x + rx, y + ry, width, height);
                } else {
                    // PASSIVE SCAN
                    hudCtx.strokeRect(x, y, width, height);
                }

                hudCtx.lineWidth = lineWidth;
                hudCtx.strokeStyle = color;
                
                // Draw Label
                hudCtx.fillStyle = color;
                const textWidth = hudCtx.measureText(text).width;
                hudCtx.fillRect(x, y - 20, textWidth + 6, 20);
                hudCtx.fillStyle = '#000';
                hudCtx.font = "bold 14px Courier New";
                hudCtx.fillText(text, x + 3, y - 5);
            });

            requestAnimationFrame(detectFrame);
        }

        // --- 4. SPECTROGRAM (Transparent Visualizer) ---
        function drawSpectrogram() {
            if (!isRunning) return;
            requestAnimationFrame(drawSpectrogram);

            mainAnalyser.getByteFrequencyData(mainData);
            
            const w = spectroCanvas.width;
            const h = spectroCanvas.height;
            const barWidth = w / mainData.length;

            // 1. CLEAR CANVAS (Crucial for transparency)
            spectroCtx.clearRect(0, 0, w, h);

            // 2. DRAW LEGENDS
            spectroCtx.fillStyle = "rgba(0, 255, 0, 0.8)";
            spectroCtx.font = "12px Courier New";
            spectroCtx.textAlign = "left";
            spectroCtx.fillText("LOW FREQ (BASS)", 10, h - 10);
            spectroCtx.textAlign = "right";
            spectroCtx.fillText("HIGH FREQ (TREBLE)", w - 10, h - 10);
            spectroCtx.textAlign = "left";
            spectroCtx.fillText("MAX (0dB)", 10, 20);

            // 3. DRAW BARS
            for (let i = 0; i < mainData.length; i++) {
                const val = mainData[i];
                const percent = val / 255;
                const barH = h * percent;

                // Color Map: Green -> Yellow -> Red
                const hue = 120 - (percent * 120);
                // Use HSLA for slight transparency on the bars themselves
                spectroCtx.fillStyle = `hsla(${hue}, 100%, 50%, 0.8)`;
                spectroCtx.fillRect(i * barWidth, h - barH, barWidth, barH);
            }
            
            // 4. DRAW WAVEFORM OVERLAY
            spectroCtx.beginPath();
            spectroCtx.strokeStyle = "rgba(255, 255, 255, 0.7)";
            spectroCtx.lineWidth = 1.5;
            spectroCtx.moveTo(0, h);
            for (let i = 0; i < mainData.length; i++) {
                const percent = mainData[i] / 255;
                spectroCtx.lineTo(i * barWidth, h - (h * percent));
            }
            spectroCtx.stroke();
        }

        // Utility: Get Average Volume
        function getVol(analyser, array) {
            if(!analyser) return 0;
            analyser.getByteFrequencyData(array);
            let sum = 0;
            for(let i=0; i<array.length; i++) sum += array[i];
            return sum / array.length;
        }

    </script>
</body>
</html>
